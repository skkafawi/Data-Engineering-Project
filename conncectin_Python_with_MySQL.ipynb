{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "import sqlalchemy as db\n",
    "import mysql.connector\n",
    "from pandas import json_normalize\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the Populations Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i used an API method here insted of the data scraping i shared just for more accurate data \n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "from pandas import json_normalize\n",
    "\n",
    "\n",
    "def get_city_info(city_names):\n",
    "    api_url = 'https://api.api-ninjas.com/v1/city'\n",
    "    api_key = '045BPSxNWDo75G4L3M3A6A==1x3VPcWgTzu4EYt1'\n",
    "    all_city_dataframes = []\n",
    "\n",
    "    for name in city_names:\n",
    "        params = {'name': name}\n",
    "        headers = {'X-Api-Key': api_key}\n",
    "\n",
    "        cities_response = requests.get(api_url, params=params, headers=headers)\n",
    "\n",
    "        if cities_response.status_code == 200:\n",
    "            cities_json = cities_response.json()\n",
    "            df = pd.DataFrame(cities_json)\n",
    "            all_city_dataframes.append(df)\n",
    "    main_city_population = pd.concat(all_city_dataframes, ignore_index=True)\n",
    "    return main_city_population\n",
    "\n",
    "# Example usage:\n",
    "city_names_list = ['Berlin', 'Paris', 'London']\n",
    "get_city_info(city_names_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = get_city_info(city_names_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inserting my data to MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_dataframe_to_mysql(df, table):\n",
    "    user='root'\n",
    "    password='S0795735786s' #type your root password here\n",
    "    host='127.0.0.1' #'127.0.0.1', # to connect to your local instance\n",
    "    database='gans' #type the name of the database you want to use here\n",
    "        \n",
    "\n",
    "    # Establish a connection to the MySQL database using SQLAlchemy engine\n",
    "    engine = create_engine(f'mysql+mysqlconnector://{user}:{password}@{host}/{database}')\n",
    "\n",
    "    try:\n",
    "        df.to_sql(table, con=engine, if_exists=\"append\", index=False)\n",
    "        print(\"succes !\")\n",
    "    except Exception as e:\n",
    "        print(f\"error : {e}\")\n",
    "\n",
    "insert_dataframe_to_mysql(city, \"cities_and_populations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting a connection for MySQL\n",
    "user='root'\n",
    "password='S0795735786s' #type your root password here\n",
    "host='127.0.0.1' #'127.0.0.1', # to connect to your local instance\n",
    "database='gans' #type the name of the database you want to use here\n",
    "engine = create_engine(f'mysql+mysqlconnector://{user}:{password}@{host}/{database}', echo=True)\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the data from my cities_and_populations in MySQL\n",
    "query = \"select * from cities_and_populations\"\n",
    "city_df = pd.read_sql(query, connection)\n",
    "city_df = pd.DataFrame(city_df)\n",
    "city_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the Weather data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weather_details(df):\n",
    "    # creating dic for the weather \n",
    "    weather_dic = {\"city_id\":[],\n",
    "                \"country\":[],\n",
    "                \"forcast_time\":[],\n",
    "                \"temperature\":[],\n",
    "                \"temperature_feels_like\":[],\n",
    "                \"outlook\":[],\n",
    "                \"outlook_description\":[],\n",
    "                \"wind_speed\":[],\n",
    "                \"wind_deg\":[],\n",
    "                \"pressure\":[],\n",
    "                \"humidity\":[],\n",
    "                \"clouds\":[],\n",
    "                \"rain\":[],\n",
    "                \"snow\":[]\n",
    "                }\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        API_key = \"155ac89acb627b07f1c68cb640aef942\"\n",
    "\n",
    "    # making a loop for the cities\n",
    "    \n",
    "        city = row[\"name\"]\n",
    "        city_id = row[\"city_id\"]\n",
    "        weather_url = (f\"http://api.openweathermap.org/data/2.5/forecast?q={city}&appid={API_key}&units=metric\")\n",
    "        weather_response = requests.get(weather_url)\n",
    "        weather_jason = weather_response.json()\n",
    "\n",
    "        # getting the information fom the Jason\n",
    "        for i in weather_jason[\"list\"]:\n",
    "            weather_dic[\"city_id\"].append(city_id)\n",
    "            weather_dic[\"country\"].append(weather_jason[\"city\"][\"country\"])\n",
    "            weather_dic[\"forcast_time\"].append(i[\"dt_txt\"])\n",
    "            weather_dic[\"temperature\"].append(i[\"main\"][\"temp\"])\n",
    "            weather_dic[\"temperature_feels_like\"].append(i[\"main\"][\"feels_like\"])\n",
    "            weather_dic[\"outlook\"].append(i[\"weather\"][0][\"main\"])\n",
    "            weather_dic[\"outlook_description\"].append(i[\"weather\"][0][\"description\"])\n",
    "            weather_dic[\"wind_speed\"].append(i[\"wind\"][\"speed\"])\n",
    "            weather_dic[\"wind_deg\"].append(i[\"wind\"][\"deg\"])\n",
    "            weather_dic[\"pressure\"].append(i[\"main\"][\"pressure\"])\n",
    "            weather_dic[\"humidity\"].append(i[\"main\"][\"humidity\"])\n",
    "            try:\n",
    "                weather_dic[\"clouds\"].append(i[\"clouds\"][\"all\"])\n",
    "            except:\n",
    "                weather_dic[\"clouds\"].append(\"0\")\n",
    "            try:\n",
    "                weather_dic[\"snow\"].append(i[\"snow\"][\"all\"])\n",
    "            except:\n",
    "                weather_dic[\"snow\"].append(\"0\")\n",
    "            try:\n",
    "                weather_dic[\"rain\"].append(i[\"rain\"][\"3h\"])\n",
    "            except:\n",
    "                weather_dic[\"rain\"].append(\"0\")  \n",
    "    return pd.DataFrame(weather_dic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = weather_details(city_df)\n",
    "weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inserting data to MySQL\n",
    "insert_dataframe_to_mysql(weather_df, \"weather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the Airports Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def icao_code_for_airports(latitudes, longitudes):\n",
    "    list_for_df=[]\n",
    "    for index, value in enumerate(latitudes):\n",
    "        airports_url = \"https://aviation-reference-data.p.rapidapi.com/airports/search\"\n",
    "\n",
    "        querystring = {\"lat\":latitudes[index],\"lon\":longitudes[index],\"radius\":\"50\"}\n",
    "\n",
    "        airports_headers = {\n",
    "            \"X-RapidAPI-Key\": \"94f5115229mshc91b32bba10ca7ap184966jsne87554a73ea6\",\n",
    "            \"X-RapidAPI-Host\": \"aviation-reference-data.p.rapidapi.com\"\n",
    "        }\n",
    "\n",
    "        airports_response = requests.get(airports_url, headers=airports_headers, params=querystring)\n",
    "        \n",
    "        list_for_df.append(pd.json_normalize(airports_response.json()))\n",
    "\n",
    "    return  pd.concat(list_for_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the same result as before but here we have the city_column appended to the table\n",
    "def icao_code_for_airports(df):\n",
    "    city_id_df=[]\n",
    "    list_for_df=[]\n",
    "    for _,row in df.iterrows():\n",
    "        latitude = row[\"latitude\"]\n",
    "        longitude = row[\"longitude\"]\n",
    "        city_id = row[\"city_id\"]\n",
    "\n",
    "\n",
    "        \n",
    "           \n",
    "        airports_url = \"https://aviation-reference-data.p.rapidapi.com/airports/search\"\n",
    "\n",
    "        querystring = {\"lat\":latitude,\"lon\":longitude,\"radius\":\"100\"}\n",
    "\n",
    "        airports_headers = {\n",
    "            \"X-RapidAPI-Key\": \"94f5115229mshc91b32bba10ca7ap184966jsne87554a73ea6\",\n",
    "            \"X-RapidAPI-Host\": \"aviation-reference-data.p.rapidapi.com\"\n",
    "        }\n",
    "\n",
    "        airports_response = requests.get(airports_url, headers=airports_headers, params=querystring).json()\n",
    "        \n",
    "        for i in range(len(airports_response)):\n",
    "            airports = {\"city_id\":city_id, \n",
    "                        \"iataCode\":airports_response[i][\"iataCode\"],\n",
    "                        \"icaoCode\":airports_response[i][\"icaoCode\"],\n",
    "                        \"name\":airports_response[i][\"name\"],\n",
    "                        \"alpha2countryCode\":airports_response[i][\"alpha2countryCode\"],\n",
    "                        \"latitude\":airports_response[i][\"latitude\"],\n",
    "                        \"longitude\":airports_response[i][\"longitude\"]}\n",
    "            list_for_df.append(airports)            \n",
    "                        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return  pd.DataFrame(list_for_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports_data = icao_code_for_airports(city_df)\n",
    "airports_data\n",
    "indices_to_remove  = [0, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45]\n",
    "airports_data = airports_data.drop(indices_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inserting the data to MySQL\n",
    "insert_dataframe_to_mysql(airports_data, \"airports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting a connection for MySQL\n",
    "user='root'\n",
    "password='S0795735786s' #type your root password here\n",
    "host='127.0.0.1' #'127.0.0.1', # to connect to your local instance\n",
    "database='gans' #type the name of the database you want to use here\n",
    "engine = create_engine(f'mysql+mysqlconnector://{user}:{password}@{host}/{database}', echo=True)\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the data from my cities_and_populations in MySQL\n",
    "query_airpots = \"select * from airports\"\n",
    "airports_df1 = pd.read_sql(query_airpots, connection)\n",
    "airports_df1 = pd.DataFrame(airports_df1)\n",
    "airports_df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the Flights Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "def get_arrival_date(response, i):\n",
    "    if 'arrivals' in response and len(response['arrivals']) > i and 'movement' in response['arrivals'][i] and 'actualTimeLocal' in response['arrivals'][i]['movement']:\n",
    "        return response['arrivals'][i]['movement']['actualTimeLocal'].split(' ')[0]\n",
    "    else:\n",
    "        return response['arrivals'][i]['movement']['scheduledTimeLocal'].split(' ')[0]\n",
    "\n",
    "def get_actual_arr_local_time(response, i):\n",
    "    if 'arrivals' in response and len(response['arrivals']) > i and 'movement' in response['arrivals'][i] and 'actualTimeLocal' in response['arrivals'][i]['movement']:\n",
    "        return response['arrivals'][i]['movement']['actualTimeLocal'].split(' ')[1].split('+')[0]\n",
    "    else:\n",
    "        return response['arrivals'][i]['movement']['scheduledTimeLocal'].split(' ')[1].split('+')[0]\n",
    "\n",
    "def get_delay_time(response, i):\n",
    "    if 'arrivals' in response and len(response['arrivals']) > i and 'movement' in response['arrivals'][i] and 'actualTimeLocal' in response['arrivals'][i]['movement']:\n",
    "        return response['arrivals'][i]['movement']['actualTimeLocal'].split(' ')[1].split('+')[1]\n",
    "    else:\n",
    "        return response['arrivals'][i]['movement']['scheduledTimeLocal'].split(' ')[1].split('+')[1]\n",
    "    \n",
    "def flights_information(df):\n",
    "    flights_data = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "\n",
    "        icao = row['icaoCode']\n",
    "        iata = row['iataCode']\n",
    "        airport_id = row['airport_id']\n",
    "        tommorow_date = (datetime.now() + timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "\n",
    "        url = f\"https://aerodatabox.p.rapidapi.com/flights/airports/icao/{icao}/{tommorow_date}T11:00/{tommorow_date}T23:00\"\n",
    "\n",
    "        querystring = {\"withLeg\":\"false\",\"direction\":\"Arrival\",\"withCancelled\":\"true\",\"withCodeshared\":\"true\",\"withCargo\":\"false\",\"withPrivate\":\"true\",\"withLocation\":\"false\"}\n",
    "\n",
    "        headers = {\n",
    "            \"X-RapidAPI-Key\": '0b7cffd425mshbf932b1b5f7e633p187a96jsna5aedb4ce276',\n",
    "            \"X-RapidAPI-Host\": \"aerodatabox.p.rapidapi.com\"\n",
    "        }\n",
    "\n",
    "        responses = requests.get(url, headers=headers, params=querystring)\n",
    "        \n",
    "        \n",
    "        \n",
    "        if responses.status_code != 200: \n",
    "            print(f\"Error - Status Code: {responses.status_code} at line{_}\")\n",
    "            print(f\"Response Content: {responses.text}\")\n",
    "            print('Problem with status code')\n",
    "            continue\n",
    "            \n",
    "        response = responses.json()\n",
    "        \n",
    "\n",
    "        for i in range(len(response['arrivals'])):\n",
    "\n",
    "            output = {\n",
    "                'airport_id': airport_id,\n",
    "                'arrival_date' : get_arrival_date(response,i),\n",
    "                'flight_number' : response['arrivals'][i]['number'],\n",
    "                'airline' : response['arrivals'][i]['airline']['name'],\n",
    "                'flight_status' : response['arrivals'][i]['status'],\n",
    "                \n",
    "                'scheduled_arr_local_time' : response['arrivals'][i]['movement']['scheduledTimeLocal'].split(' ')[1].split('+')[0],\n",
    "                \n",
    "                'actual_arr_local_time' : get_actual_arr_local_time(response, i),\n",
    "              \n",
    "                'scheduled_arr_UTC_time' : str(pd.to_datetime(response['arrivals'][i]['movement']['scheduledTimeUtc'])).split(' ')[1].split('+')[0],\n",
    "                \n",
    "                'delay_time' : get_delay_time(response, i)\n",
    "                \n",
    "            }\n",
    "\n",
    "            flights_data.append(output)\n",
    "\n",
    "    flights_df = pd.DataFrame(flights_data)\n",
    "    flights_df['scheduled_arr_local_time'] = pd.to_datetime(flights_df['scheduled_arr_local_time']).dt.time\n",
    "    flights_df['actual_arr_local_time'] = pd.to_datetime(flights_df['actual_arr_local_time']).dt.time\n",
    "    flights_df['delay_time'] = flights_df['delay_time'].apply(lambda x: datetime.strptime(x, \"%M:%S\").strftime(\"%H:%M:%S\"))\n",
    "\n",
    "    return flights_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_data = flights_information(airports_df1)\n",
    "flights_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_dataframe_to_mysql(flights_data, \"flights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
